{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f9903d04-2d52-4e59-8e02-29cfc343f0a4",
    "deepnote_cell_height": 82,
    "deepnote_cell_type": "markdown",
    "id": "Tuc9fX6MMTfG"
   },
   "source": [
    "# <center>Brief Générateur de paroles de chansons</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-064099ef-1dce-4e96-bece-2307fbfedcd7",
    "deepnote_cell_height": 70,
    "deepnote_cell_type": "markdown",
    "id": "NhJKl_JAMTfO"
   },
   "source": [
    "## Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "cell_id": "00002-67c672c1-0154-4dc6-b2b7-a4b138c598f4",
    "deepnote_cell_height": 94,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1663139342068,
    "id": "IDhKhWZdMTfQ",
    "source_hash": "7850a717"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "id": "E78Ve_JnPxme"
   },
   "outputs": [],
   "source": [
    "# with open('personal_access_token.txt') as f:\n",
    "#     ACCESS_TOKEN = f.readline()\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-244dc62d-c649-4998-bdd9-8f77263281e4",
    "deepnote_cell_height": 70,
    "deepnote_cell_type": "markdown",
    "id": "RXwKOBAhMTfV"
   },
   "source": [
    "## Importation des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dTGlXz8iOG90",
    "outputId": "87de9cc8-2064-41f3-b4a4-f1615316a093"
   },
   "outputs": [],
   "source": [
    "# !git clone -b jordan https://{ACCESS_TOKEN}@github.com/jnamor/nlp_generator>.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "wqAKLpd6MTfW",
    "outputId": "ad9106ef-a0b8-473c-d118-cd23f06780fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Songs</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Link</th>\n",
       "      <th>SName</th>\n",
       "      <th>SLink</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 Non Blondes</td>\n",
       "      <td>Rock</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>/4-non-blondes/</td>\n",
       "      <td>What's Up</td>\n",
       "      <td>/4-non-blondes/whats-up.html</td>\n",
       "      <td>Twenty-five years and my life is still\\nTrying...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 Non Blondes</td>\n",
       "      <td>Rock</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>/4-non-blondes/</td>\n",
       "      <td>Spaceman</td>\n",
       "      <td>/4-non-blondes/spaceman.html</td>\n",
       "      <td>Starry night bring me down\\nTill I realize the...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 Non Blondes</td>\n",
       "      <td>Rock</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>/4-non-blondes/</td>\n",
       "      <td>Pleasantly Blue</td>\n",
       "      <td>/4-non-blondes/pleasantly-blue.html</td>\n",
       "      <td>Every time you wake in the mornin'\\nAnd you st...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 Non Blondes</td>\n",
       "      <td>Rock</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>/4-non-blondes/</td>\n",
       "      <td>I'm The One</td>\n",
       "      <td>/4-non-blondes/im-the-one.html</td>\n",
       "      <td>Ah-hah!\\nWoo!\\nAh-ha-ha-ha-ha-ha!\\nWe came her...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 Non Blondes</td>\n",
       "      <td>Rock</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>/4-non-blondes/</td>\n",
       "      <td>Dear Mr. President</td>\n",
       "      <td>/4-non-blondes/dear-mr-president.html</td>\n",
       "      <td>I'm looking outside of my windows\\nThe view th...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Artist Genres  Songs  Popularity             Link  \\\n",
       "0  4 Non Blondes   Rock   15.0        10.1  /4-non-blondes/   \n",
       "1  4 Non Blondes   Rock   15.0        10.1  /4-non-blondes/   \n",
       "2  4 Non Blondes   Rock   15.0        10.1  /4-non-blondes/   \n",
       "3  4 Non Blondes   Rock   15.0        10.1  /4-non-blondes/   \n",
       "4  4 Non Blondes   Rock   15.0        10.1  /4-non-blondes/   \n",
       "\n",
       "                SName                                  SLink  \\\n",
       "0           What's Up           /4-non-blondes/whats-up.html   \n",
       "1            Spaceman           /4-non-blondes/spaceman.html   \n",
       "2     Pleasantly Blue    /4-non-blondes/pleasantly-blue.html   \n",
       "3         I'm The One         /4-non-blondes/im-the-one.html   \n",
       "4  Dear Mr. President  /4-non-blondes/dear-mr-president.html   \n",
       "\n",
       "                                               Lyric language  \n",
       "0  Twenty-five years and my life is still\\nTrying...       en  \n",
       "1  Starry night bring me down\\nTill I realize the...       en  \n",
       "2  Every time you wake in the mornin'\\nAnd you st...       en  \n",
       "3  Ah-hah!\\nWoo!\\nAh-ha-ha-ha-ha-ha!\\nWe came her...       en  \n",
       "4  I'm looking outside of my windows\\nThe view th...       en  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('new-dataset.csv', sep=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NAuiZoRKMTfe",
    "outputId": "a6c4ff41-f63b-4d4a-96e9-cbc98d0c6343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4672 entries, 0 to 4671\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Artist      4672 non-null   object \n",
      " 1   Genres      4672 non-null   object \n",
      " 2   Songs       4672 non-null   float64\n",
      " 3   Popularity  4672 non-null   float64\n",
      " 4   Link        4672 non-null   object \n",
      " 5   SName       4672 non-null   object \n",
      " 6   SLink       4672 non-null   object \n",
      " 7   Lyric       4672 non-null   object \n",
      " 8   language    4672 non-null   object \n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 328.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1HZJWWXMTfi",
    "outputId": "b8438f3d-2a77-43c1-b835-922a55f6ed64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4672, 9)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = [worm for word in df['Lyric'] for worm in word.split('\\n') if len(worm) > 0 and len(worm.split(' ')) <= 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(*args, fillvalue=fillvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_and_target = list(grouper(lyrics, 2, 'x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "context, target = zip(*context_and_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Preprocessing for text data\n",
    "### 2-1. Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def countWord(list_of_words):            \n",
    "    count = Counter()\n",
    "    for sentence in list_of_words:\n",
    "        for word in sentence.split():\n",
    "            count[word] += 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 33856), ('I', 27565), ('you', 23136), ('to', 18487), ('a', 17301)]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = countWord(lyrics)\n",
    "counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = max([len(x.split(' ')) for x in lyrics])\n",
    "# VOCAB_SIZE = len(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
    "\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = [clean_text(worm) for worm in context]\n",
    "decoder_inputs = [\"<BOS> \" + clean_text(worm) + \" <EOS>\" for worm in target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Make Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_text = encoder_inputs + decoder_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(complete_text)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = {v:k for k, v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(index_word) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. ONE-HOT VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_sequences = tokenizer.texts_to_sequences(encoder_inputs[:len(encoder_inputs) // 3]) \n",
    "decoder_sequences = tokenizer.texts_to_sequences(decoder_inputs[:len(decoder_inputs) // 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(encoder_sequences) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output_data = np.zeros((num_samples, MAX_LEN, VOCAB_SIZE), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4. PADDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "encoder_input_data = pad_sequences(encoder_sequences, maxlen=MAX_LEN, dtype='int32', padding='post', truncating='post')\n",
    "decoder_input_data = pad_sequences(decoder_sequences, maxlen=MAX_LEN, dtype='int32', padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-5. Word2Vec: pretrained glove vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open('../data/glove.6B.50d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimention = 50\n",
    "\n",
    "def embedding_matrix_creater(embedding_dimention, word_index):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dimention))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = embedding_matrix_creater(50, word_index=index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer weight shape (7523, 50) not compatible with provided weight shape (22569, 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-312-6b6d91e75388>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0membed_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0membed_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0membed_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\intro-conda\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1755\u001b[0m         \u001b[0mref_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1756\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mref_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1757\u001b[1;33m           raise ValueError(\n\u001b[0m\u001b[0;32m   1758\u001b[0m               \u001b[1;34m'Layer weight shape %s not compatible with provided weight '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1759\u001b[0m               'shape %s' % (ref_shape, weight.shape))\n",
      "\u001b[1;31mValueError\u001b[0m: Layer weight shape (7523, 50) not compatible with provided weight shape (22569, 50)"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embed_layer = Embedding(input_dim=VOCAB_SIZE, output_dim=50, trainable=True,)\n",
    "embed_layer.build((None,))\n",
    "embed_layer.set_weights([embedding_matrix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Build Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, LSTM, TimeDistributed\n",
    "from keras.models import Model\n",
    "\n",
    "def seq2seq_model_builder(HIDDEN_DIM=300):\n",
    "    \n",
    "    encoder_inputs = Input(shape=(MAX_LEN, ), dtype='int32',)\n",
    "    encoder_embedding = embed_layer(encoder_inputs)\n",
    "    encoder_LSTM = LSTM(HIDDEN_DIM, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder_LSTM(encoder_embedding)\n",
    "    \n",
    "    decoder_inputs = Input(shape=(MAX_LEN, ), dtype='int32',)\n",
    "    decoder_embedding = embed_layer(decoder_inputs)\n",
    "    decoder_LSTM = LSTM(HIDDEN_DIM, return_state=True, return_sequences=True)\n",
    "    decoder_outputs, _, _ = decoder_LSTM(decoder_embedding, initial_state=[state_h, state_c])\n",
    "    \n",
    "    outputs = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))(decoder_outputs)\n",
    "    model = Model([encoder_inputs, decoder_inputs], outputs)\n",
    "    model.compile(optimizer='adam', loss ='categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = seq2seq_model_builder(HIDDEN_DIM=300)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([encoder_input_data, decoder_input_data],\n",
    "                     decoder_output_data,\n",
    "                     epochs=EPOCHS, \n",
    "                     batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('seq2seq.json',\"w\").write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"chatbot_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "49b090cd-0f47-47d2-9621-f6edf89013ae",
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c91d25207c3c51aa5a26cd27f604ae441fb9f6937695f74ebf58dab3f5f24fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
